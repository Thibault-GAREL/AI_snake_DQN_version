# ğŸš— Driving AI with Deep Q-learning
This project showcases an AI that learns to drive a car in a 2D environment using the deep Q-learning algorithm. No hardcoded pathfinding â€” the agent improves by trial, error, and reward-based learning. ğŸ§ ğŸ“ˆ

  
# ğŸ§  What It Does
ğŸ® The AI controls a car in a Pygame environment with basic physics and obstacles.

ğŸ§  It uses a Deep Q-Network to estimate the best action to take from any given state.

ğŸ§¾ Inputs include distance to next checkpoint, velocity, distance to obstacles, and relative angles to next checkpoint.

ğŸ¯ Rewards are given based on life time, distance to the next checkpoint, avoiding collisions, velocity to encourage speed and reaching checkpoints.

  
# ğŸš€ Features
  ğŸ¤– Uses Deep Q-Learning with experience replay and epsilon-greedy exploration

  ğŸ§± Neural network approximates Q-values for discrete actions (e.g., accelerate, turn left/right)


Here is an image of what it looks like :

![Image_cars](Images/Img_car.png)

# ğŸ“¦ Dependencies
  - Python 3.x ğŸ
  - pytorch for neurons ğŸ§ 
  - numpy for tracking and plotting results ğŸ“Š
  - pygame for visualization ğŸ®

# ğŸ“ Notes & Observations
â³ Training is unstable at first â€” the car often spins out or crashes quickly â€” but over time, it learns to stabilize, turn properly, and sometimes follow simple roads or avoid walls.

ğŸ›ï¸ Hyperparameters (learning rate, epsilon decay, reward shaping) have a huge impact on learning performance.

Here, we can see that over 100 steps, the best path have been found (in just more than 5 min).


